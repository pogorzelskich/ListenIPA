{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CMxdGytbc5Be"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"
      ],
      "metadata": {
        "id": "CMxdGytbc5Be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "SR = 11025\n",
        "N_FFT = 1024\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞\n",
        "def audio_reformatting(audio_path:str=\"./audio.mp3\"):\n",
        "    y, _ = librosa.load(audio_path, sr=SR)\n",
        "    D_transpose_npy = np.transpose(librosa.stft(y, n_fft=N_FFT))\n",
        "    return D_transpose_npy\n"
      ],
      "metadata": {
        "id": "TmQymMxGRpQM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CRITERIA_NAMES = [[\"Thinking\", \"thi\", 2],\n",
        "                  [\"Space\", \"spa\", 2],\n",
        "                  [\"Long\", \"lon\", 2],\n",
        "                  [\"Stress\", \"str\", 2],\n",
        "                  [\"Consonant (Open, Close, Approximant, Non-sibilant fricative)\", \"con\", 9],\n",
        "                  [\"Nasal\", \"nas\", 2],\n",
        "                  [\"Plosive\", \"plo\", 2],\n",
        "                  [\"Sibilant fricative\", \"sib\", 2],\n",
        "                  [\"Trill\", \"tri\", 2],\n",
        "                  [\"Lateral\", \"lat\", 2],\n",
        "                  [\"Labialization, Rounded\", \"lbz\", 3],\n",
        "                  [\"Bilabial\", \"bil\", 2],\n",
        "                  [\"Dental\", \"den\", 2],\n",
        "                  [\"Alveolar\", \"alv\", 2],\n",
        "                  [\"Retroflex, Rhotic\", \"ret\", 2],\n",
        "                  [\"Palatal, Front\", \"pal\", 2],\n",
        "                  [\"Velar, Back\", \"vel\", 2],\n",
        "                  [\"Uvular\", \"uvu\", 2],\n",
        "                  [\"Pharyngeal/epiglottal\", \"pha\", 2],\n",
        "                  [\"Glottal\", \"glo\", 2],\n",
        "                  [\"Aspiration\", \"asp\", 2],\n",
        "                  [\"Voiceless\", \"vls\", 2]\n",
        "                  ]\n",
        "CRITERIA_TAGS_ID = {i[1]: n for n, i in enumerate(CRITERIA_NAMES)}\n",
        "CRITERIA_LEN = len(CRITERIA_NAMES)\n",
        "\n",
        "COMBINATION_CRITERIA_NAMES = [[\"Tap/flap\", \"tap\", 2],\n",
        "                              [\"Labiodental\", \"lad\", 2],\n",
        "                              [\"Postalveolar\", \"plv\", 2]\n",
        "                              ]\n",
        "COMBINATION_CRITERIA_TAGS_ID = {i[1]: n for n, i in enumerate(COMBINATION_CRITERIA_NAMES)}\n",
        "COMBINATION_CRITERIA_LEN = len(COMBINATION_CRITERIA_NAMES)\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import librosa\n",
        "# import soundfile as sf\n",
        "\n",
        "# Common sounds collection for classifying\n",
        "class SoundClassifying:\n",
        "    def __init__(self):\n",
        "        with open('data/ipa_symbols.txt', 'r', encoding=\"utf8\") as f:\n",
        "            self.symbols_table = {i[0]: [float(j) for j in i[1:]] for i in [i[:-1].split(\"\\t\") for i in f.readlines()]}\n",
        "        with open('data/ipa_mods.txt', 'r', encoding=\"utf8\") as f:\n",
        "            self.mods_table = {i[0]: [j for j in i[1:]] for i in [i[:-1].split(\"\\t\") for i in f.readlines()]}\n",
        "    def symbol_info(self, sym): return self.symbols_table[sym].copy()\n",
        "    def mod_info(self, sym): return self.mods_table[sym].copy()\n",
        "    def empty(self): return [0.0 for i in CRITERIA_NAMES]\n",
        "\n",
        "# Creating all combinantions\n",
        "def combs(a):\n",
        "    if len(a) == 0:\n",
        "        return [[]]\n",
        "    cs = []\n",
        "    for c in combs(a[1:]):\n",
        "        cs += [c, c+[a[0]]]\n",
        "    return cs\n",
        "\n",
        "# Diversifying notation with including and excluding values in brackets\n",
        "def brackets_split(notation):\n",
        "    notation_split = [i.split(\")\") for i in notation.split(\"(\")]\n",
        "    if len(notation_split) != 1:\n",
        "        notation_start = notation_split[0][0]\n",
        "        notation_split = notation_split[1:]\n",
        "        notation_combs = combs(range(len(notation_split)))\n",
        "        notation_split_vars = []\n",
        "        for c_list in notation_combs:\n",
        "            new_notation_var = notation_start\n",
        "            for n, section in enumerate(notation_split):\n",
        "                if n in c_list:\n",
        "                    new_notation_var += section[0]\n",
        "                new_notation_var += section[1]\n",
        "            notation_split_vars.append(new_notation_var)\n",
        "    else:\n",
        "        notation_split_vars = notation_split[0]\n",
        "    return notation_split_vars\n",
        "\n",
        "# Main classification function\n",
        "def classify(notation_stage_1:str, classifying:SoundClassifying, amplify:float=1.0, reverse:bool=False, bias:float=0.0):\n",
        "    vowels = [\"i\", \"y\", \"…®\", \" â\", \"…Ø\", \"u\", \"…™\", \" è\", \" ä\", \"e\", \"√∏\",\n",
        "              \"…ò\", \"…µ\", \"…§\", \"o\", \"…ô\", \"…ö\", \"…õ\", \"≈ì\", \"…ú\", \"…ù\", \"…û\",\n",
        "              \" å\", \"…î\", \"√¶\", \"…ê\", \"a\", \"…∂\", \"√§\", \"…ë\", \"…í\", \"Ã©\"]\n",
        "    curr_weight = 1.0\n",
        "    sound_symbols = classifying.symbols_table.keys()\n",
        "    sound_mods = classifying.mods_table.keys()\n",
        "\n",
        "    # Initial notation\n",
        "    notation_stage_2 = []\n",
        "    for char in notation_stage_1:\n",
        "        if char == \" \":\n",
        "            curr_classifying = classifying.empty()\n",
        "            curr_classifying[CRITERIA_TAGS_ID[\"spa\"]] = 1.0\n",
        "            curr_classifying[CRITERIA_TAGS_ID[\"lon\"]] = 0.0\n",
        "            notation_stage_2.append([[\"_\", char, \"l\"], curr_weight, curr_classifying])\n",
        "        elif char == \"|\":\n",
        "            curr_classifying = classifying.empty()\n",
        "            curr_classifying[CRITERIA_TAGS_ID[\"spa\"]] = 1.0\n",
        "            curr_classifying[CRITERIA_TAGS_ID[\"lon\"]] = 1.0\n",
        "            notation_stage_2.append([[\"_\", char, \"l\"], curr_weight, curr_classifying])\n",
        "        elif char == \"‚Äø\":\n",
        "            curr_classifying = classifying.empty()\n",
        "            curr_classifying[CRITERIA_TAGS_ID[\"spa\"]] = 1.0\n",
        "            curr_classifying[CRITERIA_TAGS_ID[\"lon\"]] = 0.0\n",
        "            notation_stage_2.append([[\"_\", char, \"s\"], curr_weight, curr_classifying])\n",
        "        elif char in sound_symbols:\n",
        "            if char in vowels:\n",
        "                notation_stage_2.append([[\"s\", char, \"v\"], curr_weight, classifying.symbol_info(char)])\n",
        "            else:\n",
        "                notation_stage_2.append([[\"s\", char, \"c\"], curr_weight, classifying.symbol_info(char)])\n",
        "        elif \"‚óå\"+char in sound_mods:\n",
        "                notation_stage_2.append([[\"m\", char, \"‚Üê\"], curr_weight, classifying.mod_info(\"‚óå\"+char)])\n",
        "        elif char in sound_mods:\n",
        "            notation_stage_2.append([[\"m\", char, \"‚Üí\"], curr_weight, classifying.mod_info(char)])\n",
        "    notation_stage_3 = []\n",
        "    for sound in notation_stage_2:\n",
        "        if sound[0][0] == \"m\":\n",
        "            if sound[0][2] == \"‚Üê\":\n",
        "                last_sound = notation_stage_3[-1].copy()\n",
        "                last_sound[0] = last_sound[0].copy()\n",
        "                last_sound[2] = last_sound[2].copy()\n",
        "                for cat, val in enumerate(sound[2]):\n",
        "                    if val == \"\":\n",
        "                        last_sound[0][1] = notation_stage_3[-1][0][1] + sound[0][1]\n",
        "                    elif val[0] == \"-\":\n",
        "                        last_sound[0][1] = notation_stage_3[-1][0][1] + sound[0][1]\n",
        "                        last_sound[2][cat] = notation_stage_3[-1][2][cat] - float(val[1:])\n",
        "                        if last_sound[2][cat] < 0: last_sound[2][cat] = 0\n",
        "                    elif val[0] == \"+\":\n",
        "                        last_sound[0][1] = notation_stage_3[-1][0][1] + sound[0][1]\n",
        "                        last_sound[2][cat] = notation_stage_3[-1][2][cat] + float(val[1:])\n",
        "                        if last_sound[2][cat] > 1: last_sound[2][cat] = 1\n",
        "                    elif val[:3] == \"to \":\n",
        "                        last_sound[0][1] = notation_stage_3[-1][0][1] + sound[0][1]\n",
        "                        last_sound[2][cat] = (notation_stage_3[-1][2][cat] + float(val[3:])) / 2\n",
        "                    elif val[:3] == \"up \":\n",
        "                        last_sound[0][1] = notation_stage_3[-1][0][1] + sound[0][1]\n",
        "\n",
        "                        curr_val = notation_stage_3[-1][2][cat]\n",
        "                        new_val = float(val[3:])\n",
        "                        if curr_val < new_val:\n",
        "                            last_sound[2][cat] = new_val\n",
        "                    else:\n",
        "                        last_sound[0][1] = notation_stage_3[-1][0][1] + sound[0][1]\n",
        "                        last_sound[2][cat] = float(val)\n",
        "                notation_stage_3[-1] = last_sound\n",
        "            else:\n",
        "                notation_stage_3.append(sound)\n",
        "        else:\n",
        "            notation_stage_3.append(sound)\n",
        "\n",
        "    # Adding mods\n",
        "    notation_stage_4 = []\n",
        "    for sound in notation_stage_3[::-1]:\n",
        "        if sound[0][0] == \"m\":\n",
        "            if sound[0][2] == \"‚Üí\":\n",
        "                for n in range(len(notation_stage_4)):\n",
        "                    n_rev = len(notation_stage_4) - n - 1\n",
        "                    if notation_stage_4[n_rev][0][0] != \"s\" or \"ÃØ\" in notation_stage_4[n_rev][0][1]:\n",
        "                        pass\n",
        "                    elif \"Ã©\" in notation_stage_4[n_rev][0][1] or \\\n",
        "                    notation_stage_4[n_rev][2][CRITERIA_TAGS_ID[\"con\"]] < 0.8125:\n",
        "                        notation_stage_4[n_rev][0][1] = sound[0][1] + notation_stage_4[n_rev][0][1]\n",
        "                        for s in range(len(sound[2])):\n",
        "                            if sound[2][s] != \"\":\n",
        "                                notation_stage_4[n_rev][2][s] += float(sound[2][s]) * sound[1]\n",
        "                        break\n",
        "            else:\n",
        "                notation_stage_4.append(sound)\n",
        "        else:\n",
        "            notation_stage_4.append(sound)\n",
        "\n",
        "    notation_stage_4 = notation_stage_4[::-1]\n",
        "\n",
        "    # Stress (strtucture of words)\n",
        "    structure = \"\"\n",
        "    for sound in notation_stage_4:\n",
        "        if sound[0][0] == \"_\" and sound[2][CRITERIA_TAGS_ID[\"lon\"]] > 0.375:\n",
        "            structure += \"_\"\n",
        "        elif sound[0][0] == \"_\":\n",
        "            structure += \"-\"\n",
        "        elif sound[0][0] == \"s\":\n",
        "            if (sound[0][2] == \"v\" or \"Ã©\" in sound[0][1]) and \"ÃØ\" not in sound[0][1]:\n",
        "                if sound[2][CRITERIA_TAGS_ID[\"str\"]] > 0:\n",
        "                    structure += \"V\"\n",
        "                else:\n",
        "                    structure += \"v\"\n",
        "            elif (sound[0][2] == \"c\" or \"ÃØ\" in sound[0][1]) and \"Ã©\" not in sound[0][1]:\n",
        "                structure += \"c\"\n",
        "        else:\n",
        "            structure += \"o\"\n",
        "\n",
        "    # Stress (stressing needed sounds)\n",
        "    structure_check = [[0]*len(i)+[\"_\"] if \"v\" in i and i.count(\"v\") == 1 and i.count(\"V\") == 0\n",
        "                       else [1]*len(i)+[\"_\"] for i in structure.split(\"_\")]\n",
        "    structure_list = []\n",
        "    for i in structure_check:\n",
        "        structure_list += i\n",
        "    structure_list = structure_list[:-1]\n",
        "\n",
        "    stressed = False\n",
        "    for n, struc in enumerate(structure_list):\n",
        "        if struc == 0 and not stressed:\n",
        "            if structure[n] == \"v\":\n",
        "                notation_stage_4[n][2][CRITERIA_TAGS_ID[\"str\"]] = 1.0\n",
        "                stressed = True\n",
        "        elif struc == \"_\":\n",
        "            stressed = False\n",
        "\n",
        "    # Long sounds\n",
        "    if len(notation_stage_4) != 0:\n",
        "        notation_stage_5 = [notation_stage_4[0].copy()]\n",
        "    else:\n",
        "        notation_stage_5 = []\n",
        "    for n in range(1, len(notation_stage_4)):\n",
        "        sound1 = notation_stage_4[n][2].copy()\n",
        "        sound2 = notation_stage_5[-1][2].copy()\n",
        "        sound1[CRITERIA_TAGS_ID[\"lon\"]] = 0.0\n",
        "        sound2[CRITERIA_TAGS_ID[\"lon\"]] = 0.0\n",
        "        stress1 = sum([i in notation_stage_4[n][0][1] for i in \"ÀåÀà\"]) == 0\n",
        "        stress2 = sum([i in notation_stage_5[-1][0][1] for i in \"ÀåÀà\"]) == 0\n",
        "        cv1 = \"Ã©\" in notation_stage_4[n][0][1]\n",
        "        cv2 = \"Ã©\" in notation_stage_5[-1][0][1]\n",
        "        vc1 = \"ÃØ\" in notation_stage_4[n][0][1]\n",
        "        vc2 = \"ÃØ\" in notation_stage_5[-1][0][1]\n",
        "        if sound1 == sound2 and (stress1 and stress2) and cv1 == cv2 and vc1 == vc2:\n",
        "            notation_stage_5[-1][0][1] += notation_stage_4[n][0][1]\n",
        "            notation_stage_5[-1][2][CRITERIA_TAGS_ID[\"lon\"]] = 1.0\n",
        "        else:\n",
        "            notation_stage_5.append(notation_stage_4[n])\n",
        "\n",
        "    # Removing spaces from in the beginning and in the end\n",
        "    notation_stage_6 = []\n",
        "    no_longer_spaces = False\n",
        "    for sound in notation_stage_5:\n",
        "        if sound[2][CRITERIA_TAGS_ID[\"spa\"]] != 1.0:\n",
        "            no_longer_spaces = True\n",
        "        if no_longer_spaces:\n",
        "            notation_stage_6.append(sound)\n",
        "    notation_stage_7 = []\n",
        "    no_longer_spaces = False\n",
        "    for sound in notation_stage_6[::-1]:\n",
        "        if sound[2][CRITERIA_TAGS_ID[\"spa\"]] != 1.0:\n",
        "            no_longer_spaces = True\n",
        "        if no_longer_spaces:\n",
        "            notation_stage_7.append(sound)\n",
        "    notation_stage_7 = notation_stage_7[::-1]\n",
        "\n",
        "    # Multiplying and reversing\n",
        "    notation_stage_amp = []\n",
        "    for sound in notation_stage_7:\n",
        "        if reverse:\n",
        "            for cat in range(len(sound[2])):\n",
        "                sound[2][cat] = amplify - (amplify * sound[2][cat]) + bias\n",
        "        else:\n",
        "            for cat in range(len(sound[2])):\n",
        "                sound[2][cat] = amplify * sound[2][cat] + bias\n",
        "        notation_stage_amp.append(sound)\n",
        "\n",
        "    return notation_stage_amp\n",
        "\n",
        "# Dataset collect\n",
        "class ListenIPADataset(Dataset):\n",
        "    def __init__(self, notations:list, amplify:float=1.0, reverse:bool=False, bias:float=0.0):\n",
        "        self.classifying = SoundClassifying()\n",
        "        self.amplify = amplify\n",
        "        self.reverse = reverse\n",
        "        self.bias = bias\n",
        "        self.pairs = notations\n",
        "\n",
        "    def append(self, pair):\n",
        "        self.pairs.append(pair)\n",
        "\n",
        "    def pop(self, index:int=-1):\n",
        "        self.pairs.pop(index)\n",
        "\n",
        "    def criteria_max(self):\n",
        "        return self.bias if self.reverse else self.amplify+self.bias\n",
        "\n",
        "    def criteria_min(self):\n",
        "        return self.amplify+self.bias if self.reverse else self.bias\n",
        "\n",
        "    def thinking_empty(self):\n",
        "        if self.reverse:\n",
        "            returning_array = [self.bias] + [self.amplify + self.bias for i in CRITERIA_NAMES[1:]]\n",
        "        else:\n",
        "            returning_array = [self.amplify + self.bias] + [self.bias for i in CRITERIA_NAMES[1:]]\n",
        "\n",
        "        return tuple(returning_array)\n",
        "\n",
        "    def output_audio_npy(self, index:int):\n",
        "        return np.load(f'data/audio_data_stft/{self.pairs[index][0]}.npy')\n",
        "\n",
        "    def output_audio_mp3(self, index:int, curr_sr:int=SR):\n",
        "        return librosa.load(f'data/audio_data/{self.pairs[index][0]}.mp3', sr=curr_sr)\n",
        "        # y, sr = librosa.load(self.pairs[index][0], sr=curr_sr)\n",
        "\n",
        "    def output_labels(self, index:int, is_shortened=True):\n",
        "        curr_weights = [brackets_split(i[1:-1].strip()) for ipa_id, i in self.pairs[index][1]]\n",
        "        t = []\n",
        "        if is_shortened:\n",
        "            for weight in curr_weights:\n",
        "                for variant in [[i2[2] for i2 in classify(i1, self.classifying, self.amplify, self.reverse, self.bias)] for i1 in weight]:\n",
        "                    t.append(tuple([tuple(k) for k in variant]))\n",
        "        else:\n",
        "            for weight in curr_weights:\n",
        "                for variant in [[i2 for i2 in classify(i1, self.classifying, self.amplify, self.reverse, self.bias)] for i1 in weight]:\n",
        "                    t.append(tuple([(tuple(k[0]), k[1], tuple(k[2])) for k in variant]))\n",
        "        return tuple(set(t))\n",
        "\n",
        "    def output_audio_id(self, index:int):\n",
        "        return self.pairs[index][0]\n",
        "\n",
        "    def output_labels_text(self, index:int):\n",
        "        return self.pairs[index][1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, index:int):\n",
        "        return {\"audio\": self.output_audio_npy(index), \"labels\": self.output_labels(index),\n",
        "                \"audio_id\": self.output_audio_id(index), \"labels_text\": self.output_labels_text(index)}\n"
      ],
      "metadata": {
        "id": "VNBZmjSURVf9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import complex64\n",
        "\n",
        "\n",
        "class ListenIPA(nn.Module):\n",
        "    def __init__(self, audio_input_size, criteria_len, kernel_size, num_layers, is_var1):\n",
        "        super(ListenIPA, self).__init__()\n",
        "        self.audio_input_size = audio_input_size\n",
        "        self.criteria_len = criteria_len\n",
        "        self.new_hidden_size = 129\n",
        "        self.kernel_size = kernel_size\n",
        "        self.num_layers = num_layers\n",
        "        self.is_var1 = is_var1\n",
        "\n",
        "        if is_var1:\n",
        "            self.conv1 = nn.Conv1d(1, 1, kernel_size=kernel_size, stride=kernel_size//7,\n",
        "                                   padding=kernel_size//2, dtype=complex64, bias=False)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv1d(1, 1, kernel_size=kernel_size, stride=kernel_size//7,\n",
        "                                   padding=kernel_size//2, dtype=complex64, bias=True)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(1, 1, kernel_size=kernel_size, stride=kernel_size//7,\n",
        "                               padding=kernel_size//2, dtype=complex64, bias=False)\n",
        "\n",
        "        self.initial_linears2 = nn.Sequential(\n",
        "            nn.Linear(self.new_hidden_size * 2, self.new_hidden_size, bias=False),\n",
        "            nn.Linear(self.new_hidden_size, self.new_hidden_size, bias=False),\n",
        "        )\n",
        "\n",
        "        if is_var1:\n",
        "            self.recc = nn.LSTM(self.new_hidden_size, self.new_hidden_size, num_layers, batch_first=False)\n",
        "        else:\n",
        "            self.recc = nn.GRU(self.new_hidden_size, self.new_hidden_size, num_layers, batch_first=False)\n",
        "\n",
        "        self.final_linears1 = nn.Sequential(\n",
        "            nn.Linear(self.new_hidden_size, criteria_len, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.cat((x.real, x.imag), dim=-1)\n",
        "        x = self.initial_linears2(x)\n",
        "        x, hidden = self.recc(x, hidden)\n",
        "        x = self.final_linears1(x)\n",
        "        return x, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        if self.is_var1:\n",
        "            return (torch.zeros(self.num_layers, 1, self.new_hidden_size),\n",
        "                    torch.zeros(self.num_layers, 1, self.new_hidden_size))\n",
        "        else:\n",
        "            return torch.zeros(self.num_layers, 1, self.new_hidden_size)"
      ],
      "metadata": {
        "id": "Oj60P4ayRSiQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vowels_table = [[[\"i\",\"iÃπ\",\"y\"], [\"…®\",\"…®Ãπ\",\" â\"], [\"…Ø\",\"uÃú\",\"u\"]],\n",
        "                [[\"…™\",\"…™Ãπ\",\" è\"], [\"…™Ãà\",\"…™ÃàÃπ\",\" èÃà\"], [\"…ØÃΩ\",\" äÃú\",\" ä\"]],\n",
        "                [[\"e\",\"eÃπ\",\"√∏\"], [\"…ò\",\"…òÃπ\",\"…µ\"], [\"…§\",\"oÃú\",\"o\"]],\n",
        "                [[\"eÃû\",\"eÃπÃû\",\"√∏Ãû\"], [\"…ôÃú\",\"…ô\",\"…ôÃπ\"], [\"…§Ãû\",\"oÃúÃû\",\"oÃû\"]],\n",
        "                [[\"…õ\",\"…õÃπ\",\"≈ì\"], [\"…ú\",\"…úÃπ\",\"…û\"], [\" å\",\"…îÃú\",\"…î\"]],\n",
        "                [[\"√¶\",\"√¶Ãπ\",\"≈ìÃû\"], [\"√¶Ãà\",\"…ê\",\"…êÃπ\"], [\" åÃû\",\"…îÃúÃû\",\"…îÃû\"]],\n",
        "                [[\"a\",\"aÃπ\",\"…∂\"], [\"√§\",\"√§Ãπ\",\"…∂Ãà\"], [\"…ë\",\"…íÃú\",\"…í\"]]]\n",
        "\n",
        "MODS_TABLE_ADD = {\"approx\": \"Ãû\", \"nasal\": \"ÃÉ\", \"plosive\": \"Õê\", \"sibilant\": \"Õí\", \"non-sib fr\":\"Ãê\", \"trill\": \"Õô\", \"tap\": \"Õì\",\n",
        "              \"dental\": \"Ã™\", \"alveolar\": \"Õá\", \"half_labialization\": \"Ãπ\", \"retroflex\": \"Àû\"}\n",
        "SUB_TABLE_ADD = {\"lateral\": \"À°\", \"labialization\": \" ∑\", \"bilabial\": \"·µô\", \"labiodental\": \"·∂π\", \"palatal\": \" ≤\", \"velar\": \"À†\",\n",
        "              \"uvular\": \" ∂\", \"pharyngeal\": \"À§\", \"glottal\": \"ÀÄ\", \"aspiration\": \" ∞\"} #\"labialization\": \"·µù\"\n",
        "\n",
        "l_sounds = [[\"approx\", [[\"dental\", \"lÃ™ lÃ™Ãä\"], [\"postalveolar\", \"lÃ† lÃ†Ãä\"],\n",
        "                        [\"alveolar\", \"l lÃ•\"], [\"retroflex\", \"…≠ …≠Ãä\"],\n",
        "                        [\"velar\", \" ü  üÃ•\"], [\"uvular\", \" üÃ†  üÃ†Ãä\"],\n",
        "                        [\"palatal\", \" é  éÃ•\"]]],\n",
        "            [\"tap\",[[\"dental\", \"…∫Ã™ …∫Ã™Ãä\"], [\"postalveolar\", \"…∫Ã† …∫Ã†Ãä\"],\n",
        "                    [\"alveolar\", \"…∫ …∫Ã•\"], [\"retroflex\", \"ùºà ùºàÃ•\"],\n",
        "                    [\"velar\", \" üÃÜ  üÃÜÃ•\"], [\"uvular\", \" üÃ†ÃÜ  üÃ†ÃÜÃ•\"],\n",
        "                    [\"palatal\", \" éÃÜ  éÃÜÃ•\"]]],\n",
        "            [\"sibilant\",   [[\"dental\", \" ´Ã™  ™Ã™\"], [\"postalveolar\", \" ´Ã†  ™Ã†\"],\n",
        "                            [\"alveolar\", \" ´  ™\"], [\"retroflex\", \" ´Ã¢  ™Ã¢\"]]],\n",
        "            [\"non-sib fr\", [[\"dental\", \"lÃ™Ãù lÃ™ÃäÃù\"], [\"postalveolar\", \"lÃ†Ãù lÃ†ÃäÃù\"],\n",
        "                            [\"alveolar\", \"…Æ …¨\"], [\"retroflex\", \"ùºÖ Íûé\"],\n",
        "                            [\"velar\", \"ùºÑÃ¨ ùºÑ\"], [\"uvular\", \" üÃ†Ãù  üÃ†ÃäÃù\"],\n",
        "                            [\"palatal\", \"ùºÜÃ¨ ùºÜ\"]]]]\n",
        "p_sounds = [[\"approx\", [[\"dental\", \"…πÃ™ …πÃ™Ãä\"], [\"postalveolar\", \"…πÃ† …πÃ†Ãä\"],\n",
        "                        [\"alveolar\", \"…π …πÃ•\"], [\"retroflex\", \"…ª …ªÃä\"],\n",
        "                        [\"labiodental\", \" ã  ãÃ•\"], [\"bilabial\", \"Œ≤Ãû …∏Ãû\"],\n",
        "                        [\"velar\", \"…∞ …∞Ãä\"], [\"uvular\", \" ÅÃû œáÃû\"],\n",
        "                        [\"palatal\", \"j jÃä\"], [\"pharyngeal\", \" ïÃû ƒßÃû\"],\n",
        "                        [\"glottal\", \" îÃ¨Ãû  îÃû\"]]],\n",
        "            [\"tap\",[[\"dental\", \"…æÃ™ …æÃ™Ãä\"], [\"postalveolar\", \"…æÃ† …æÃ†Ãä\"],\n",
        "                    [\"alveolar\", \"…æ …æÃ•\"], [\"retroflex\", \"…Ω …ΩÃä\"],\n",
        "                    [\"labiodental\", \"‚±± ‚±±Ã•\"], [\"bilabial\", \"‚±±Ãü ‚±±ÃüÃä\"],\n",
        "                    [\"velar\", \"…°ÃÜ kÃÜ\"], [\"uvular\", \"…¢ÃÜ qÃÜ\"],\n",
        "                    [\"palatal\", \"jÃÜ jÃäÃÜ\"], [\"pharyngeal\", \" ¢ÃÜ  úÃÜ\"],\n",
        "                    [\"glottal\", \" îÃ¨ÃÜ  îÃÜ\"]]],\n",
        "            [\"trill\",  [[\"dental\", \"rÃ™ rÃ™Ãä\"], [\"postalveolar\", \"rÃ† rÃ†Ãä\"],\n",
        "                        [\"alveolar\", \"r rÃ•\"], [\"retroflex\", \"…ΩÕô …ΩÃäÕô\"],\n",
        "                        [\"labiodental\", \" ôÃ™  ôÃ™Ãä\"], [\"bilabial\", \" ô  ôÃ•\"],\n",
        "                        [\"velar\", \"…°Õô kÕô\"], [\"uvular\", \" Ä  ÄÃ•\"],\n",
        "                        [\"palatal\", \"jÕô jÃäÕô\"], [\"pharyngeal\", \" ¢  ú\"],\n",
        "                        [\"glottal\", \" îÃ¨Õô  îÕô\"]]],\n",
        "            [\"sibilant\",   [[\"dental\", \"zÃ™ sÃ™\"], [\"postalveolar\", \" í  É\"],\n",
        "                            [\"alveolar\", \"z s\"], [\"retroflex\", \" ê  Ç\"],\n",
        "                            [\"labiodental\", \"*z-·∂π *s-·∂π\"], [\"bilabial\", \"*z-·µô *s-·µô\"],\n",
        "                            [\"velar\", \"*z-À† *s-À†\"], [\"uvular\", \"*z- ∂ *s- ∂\"],\n",
        "                            [\"palatal\", \"*z- ≤ *s- ≤\"], [\"pharyngeal\", \"*z-À§ *s-À§\"],\n",
        "                            [\"glottal\", \"*z-ÀÄ *s-ÀÄ\"]]],\n",
        "            [\"plosive\",[[\"dental\", \"dÃ™ tÃ™\"], [\"postalveolar\", \"dÃ† tÃ†\"],\n",
        "                        [\"alveolar\", \"d t\"], [\"retroflex\", \"…ñ  à\"],\n",
        "                        [\"labiodental\", \"»∏ »π\"], [\"bilabial\", \"b p\"],\n",
        "                        [\"velar\", \"…° k\"], [\"uvular\", \"…¢ q\"],\n",
        "                        [\"palatal\", \"…ü c\"], [\"pharyngeal\", \" °Ã¨  °\"],\n",
        "                        [\"glottal\", \" îÃ¨  î\"]]],\n",
        "            [\"nasal\",  [[\"dental\", \"nÃ™ nÃ™Ãä\"], [\"postalveolar\", \"nÃ† nÃ†Ãä\"],\n",
        "                        [\"alveolar\", \"n nÃ•\"], [\"retroflex\", \"…≥ …≥Ãä\"],\n",
        "                        [\"labiodental\", \"…± …±Ãä\"], [\"bilabial\", \"m mÃ•\"],\n",
        "                        [\"velar\", \"≈ã ≈ãÃä\"], [\"uvular\", \"…¥ …¥Ã•\"],\n",
        "                        [\"palatal\", \"…≤ …≤Ãä\"], [\"pharyngeal\", \"*n-À§ *nÃ•-À§\"],\n",
        "                        [\"glottal\", \"*n-ÀÄ *nÃ•-ÀÄ\"]]],\n",
        "            [\"non-sib fr\", [[\"dental\", \"√∞ Œ∏\"], [\"postalveolar\", \"…πÃ†Ãù …πÃ†ÃùÃä\"],\n",
        "                            [\"alveolar\", \"√∞Ã† Œ∏Ã†\"], [\"retroflex\", \"…ªÃù …ªÃùÃä\"],\n",
        "                            [\"labiodental\", \"v f\"], [\"bilabial\", \"Œ≤ …∏\"],\n",
        "                            [\"velar\", \"…£ x\"], [\"uvular\", \" Å œá\"],\n",
        "                            [\"palatal\", \" ù √ß\"], [\"pharyngeal\", \" ï ƒß\"],\n",
        "                            [\"glottal\", \"…¶ h\"]]]]\n",
        "\n",
        "\n",
        "def output_to_symbols_reformat(outputs:list, think_value=0.5, reverse=False, amplify=1.0, bias=0.0):\n",
        "    # Reverse back\n",
        "    if reverse:\n",
        "        new_outputs = []\n",
        "        for output in outputs:\n",
        "            new_outputs.append([-i+bias*2+amplify for i in output])\n",
        "        outputs = new_outputs.copy()\n",
        "\n",
        "    # Max to 1 and min to 0\n",
        "    if amplify != 1 or bias != 0:\n",
        "        new_outputs = []\n",
        "        for output in outputs:\n",
        "            new_outputs.append([(i-bias)/amplify for i in output])\n",
        "        outputs = new_outputs.copy()\n",
        "\n",
        "    # All thinking is out\n",
        "    new_outputs = []\n",
        "    for output in outputs:\n",
        "        if output[CRITERIA_TAGS_ID[\"thi\"]] <= think_value: #Not thinking\n",
        "            new_outputs.append(output)\n",
        "    outputs = new_outputs.copy()\n",
        "\n",
        "    return outputs\n",
        "\n",
        "def select_sound(symbols:str, voiceless:bool):\n",
        "    vd, vl = symbols.split(\" \")\n",
        "    return vl if voiceless else vd\n",
        "\n",
        "def sound_manner(nc:dict, manner_list:list[list], used_artic:str):\n",
        "    for manner, sounds in manner_list:\n",
        "        if nc[manner]:\n",
        "            sym = select_sound(sounds, nc[\"vl\"])\n",
        "            nc[manner], nc[used_artic] = False, False\n",
        "            return nc, sym, True\n",
        "    return nc, \"\", False\n",
        "\n",
        "def sound_artic(nc:dict, artic_list:list[list]):\n",
        "    for artic, manner_list in artic_list:\n",
        "        if nc[artic]:\n",
        "            nc, sym, ok = sound_manner(nc, manner_list, artic)\n",
        "            if ok: return nc, sym\n",
        "    return nc, \"\"\n",
        "\n",
        "def create_new_criteria_output(output):\n",
        "    nc = {}\n",
        "    nc[\"approx\"]     = True if output[CRITERIA_TAGS_ID[\"con\"]] < 0.9375 else False\n",
        "    nc[\"nasal\"]      = False if output[CRITERIA_TAGS_ID[\"nas\"]] < 0.5 else True\n",
        "    nc[\"plosive\"]    = False if output[CRITERIA_TAGS_ID[\"plo\"]] < 0.5 else True\n",
        "    nc[\"sibilant\"]   = False if output[CRITERIA_TAGS_ID[\"sib\"]] < 0.5 else True\n",
        "    nc[\"trill\"]      = False if output[CRITERIA_TAGS_ID[\"tri\"]] < 0.5 else True\n",
        "    nc[\"lateral\"]    = False if output[CRITERIA_TAGS_ID[\"lat\"]] < 0.5 else True\n",
        "    nc[\"bilabial\"]   = False if output[CRITERIA_TAGS_ID[\"bil\"]] < 0.5 else True\n",
        "    nc[\"dental\"]     = False if output[CRITERIA_TAGS_ID[\"den\"]] < 0.5 else True\n",
        "    nc[\"alveolar\"]   = False if output[CRITERIA_TAGS_ID[\"alv\"]] < 0.5 else True\n",
        "    nc[\"retroflex\"]  = False if output[CRITERIA_TAGS_ID[\"ret\"]] < 0.5 else True\n",
        "    nc[\"palatal\"]    = False if output[CRITERIA_TAGS_ID[\"pal\"]] < 0.5 else True\n",
        "    nc[\"velar\"]      = False if output[CRITERIA_TAGS_ID[\"vel\"]] < 0.5 else True\n",
        "    nc[\"uvular\"]     = False if output[CRITERIA_TAGS_ID[\"uvu\"]] < 0.5 else True\n",
        "    nc[\"pharyngeal\"] = False if output[CRITERIA_TAGS_ID[\"pha\"]] < 0.5 else True\n",
        "    nc[\"glottal\"]    = False if output[CRITERIA_TAGS_ID[\"glo\"]] < 0.5 else True\n",
        "    nc[\"aspiration\"] = False if output[CRITERIA_TAGS_ID[\"asp\"]] < 0.5 else True\n",
        "    nc[\"vl\"]         = False if output[CRITERIA_TAGS_ID[\"vls\"]] < 0.5 else True\n",
        "\n",
        "    curr_crit = output[CRITERIA_TAGS_ID[\"lbz\"]]\n",
        "    nc[\"labialization\"] = False if curr_crit < 0.75 else True\n",
        "    nc[\"half_labialization\"] = True if curr_crit > 0.25 and curr_crit <= 0.75 else False\n",
        "\n",
        "    nc[\"tap\"], nc[\"labiodental\"], nc[\"postalveolar\"], nc[\"non-sib fr\"] = False, False, False, False\n",
        "    if nc[\"plosive\"] and nc[\"trill\"]:\n",
        "        nc[\"tap\"], nc[\"plosive\"], nc[\"trill\"] = True, False, False\n",
        "    if nc[\"bilabial\"] and nc[\"dental\"]:\n",
        "        nc[\"labiodental\"], nc[\"bilabial\"], nc[\"dental\"], nc[\"alveolar\"] = True, False, False, False\n",
        "    if nc[\"alveolar\"] and nc[\"retroflex\"]:\n",
        "        nc[\"postalveolar\"], nc[\"alveolar\"], nc[\"retroflex\"] = True, False, False\n",
        "    if nc[\"dental\"] and nc[\"alveolar\"]:\n",
        "        nc[\"dental\"], nc[\"alveolar\"] = True, False\n",
        "\n",
        "    nc[\"non-sib fr\"] = not (nc[\"approx\"] or nc[\"tap\"] or nc[\"trill\"] or\n",
        "                            nc[\"sibilant\"] or nc[\"plosive\"] or nc[\"nasal\"])\n",
        "    return nc\n",
        "\n",
        "def output_to_symbols(outputs:list, think_value=0.5, ignore_first=False, reverse=False, amplify=1.0, bias=0.0, spacing=\"\"):\n",
        "    if ignore_first: outputs.pop(0)\n",
        "    outputs = output_to_symbols_reformat(outputs, think_value, reverse, amplify, bias)\n",
        "    whole_symbol_notation = \"\"\n",
        "    for output in outputs:\n",
        "        curr_sym = \"\"\n",
        "        is_vowel = False\n",
        "        is_consonant = False\n",
        "        is_space = False\n",
        "        if output[CRITERIA_TAGS_ID[\"spa\"]] >= 0.5: #Space\n",
        "            is_space = True\n",
        "            curr_sym = \" \" if output[CRITERIA_TAGS_ID[\"lon\"]] < 0.5 else \"|\"\n",
        "        elif output[CRITERIA_TAGS_ID[\"con\"]] < 0.8125: # Vowel\n",
        "            is_vowel = True\n",
        "        else:\n",
        "            is_consonant = True\n",
        "\n",
        "        if is_consonant:\n",
        "            nc = create_new_criteria_output(output)\n",
        "\n",
        "            if nc[\"alveolar\"] and nc[\"velar\"] and nc[\"lateral\"] and nc[\"approx\"]:\n",
        "                curr_sym = select_sound(\"…´ …´Ã•\", nc[\"vl\"])\n",
        "                nc[\"alveolar\"], nc[\"velar\"], nc[\"lateral\"], nc[\"approx\"] = False, False, False, False\n",
        "            elif nc[\"labialization\"] and nc[\"velar\"] and nc[\"approx\"]:\n",
        "                curr_sym = select_sound(\"w  ç\", nc[\"vl\"])\n",
        "                nc[\"labialization\"], nc[\"velar\"], nc[\"approx\"] = False, False, False\n",
        "            elif nc[\"labialization\"] and nc[\"palatal\"] and nc[\"approx\"]:\n",
        "                curr_sym = select_sound(\"…• …•Ãä\", nc[\"vl\"])\n",
        "                nc[\"labialization\"], nc[\"palatal\"], nc[\"approx\"] = False, False, False\n",
        "            elif nc[\"postalveolar\"] and nc[\"palatal\"] and nc[\"sibilant\"] and not nc[\"approx\"]:\n",
        "                curr_sym = select_sound(\" ë …ï\", nc[\"vl\"])\n",
        "                nc[\"postalveolar\"], nc[\"palatal\"], nc[\"sibilant\"] = False, False, False\n",
        "            else:\n",
        "                if nc[\"lateral\"]:\n",
        "                    nc, curr_sym = sound_artic(nc, l_sounds)\n",
        "                    if curr_sym != \"\":\n",
        "                        nc[\"lateral\"] = False\n",
        "                else:\n",
        "                    nc, curr_sym = sound_artic(nc, p_sounds)\n",
        "\n",
        "        if is_vowel:\n",
        "            nc = create_new_criteria_output(output)\n",
        "            nc[\"approx\"] = False\n",
        "\n",
        "            roundness = 2 if nc[\"labialization\"] else 1 if nc[\"half_labialization\"] else 0\n",
        "            nc[\"labialization\"], nc[\"half_labialization\"] = False, False\n",
        "\n",
        "            backness = 1 if nc[\"palatal\"] == nc[\"velar\"] else 0 if nc[\"palatal\"] else 2\n",
        "            nc[\"palatal\"], nc[\"velar\"] = False, False\n",
        "\n",
        "            curr_crit = output[CRITERIA_TAGS_ID[\"con\"]]\n",
        "            curr_crit = 0 if curr_crit < 0 else 0.75 if curr_crit > 0.75 else curr_crit\n",
        "            curr_crit = curr_crit * 16 + 1\n",
        "            closeness = 6 - int(curr_crit // 2)\n",
        "\n",
        "            curr_sym = vowels_table[closeness][backness][roundness]\n",
        "            if nc[\"retroflex\"]:\n",
        "                if \"…ô\" in curr_sym:\n",
        "                    curr_sym = curr_sym.replace(\"…ô\", \"…ö\")\n",
        "                elif \"…ú\" in curr_sym:\n",
        "                    curr_sym = curr_sym.replace(\"…ú\", \"…ù\")\n",
        "                else:\n",
        "                    curr_sym += \"Àû\"\n",
        "            nc[\"retroflex\"] = False\n",
        "\n",
        "            if nc[\"vl\"]:\n",
        "                if \"y\" in curr_sym or \"Ãπ\" in curr_sym or \"Ãû\" in curr_sym:\n",
        "                    curr_sym += \"Ãä\"\n",
        "                else:\n",
        "                    curr_sym += \"Ã•\"\n",
        "\n",
        "        if not is_space:\n",
        "            if curr_sym == \"\":\n",
        "                curr_sym = \"‚óå\"\n",
        "\n",
        "            curr_sym_split = curr_sym.split(\"-\", 1)\n",
        "            if len(curr_sym_split) == 1: curr_sym_split.append(\"\")\n",
        "\n",
        "            for i in MODS_TABLE_ADD:\n",
        "                if nc[i]:\n",
        "                    curr_sym_split[0] += MODS_TABLE_ADD[i]\n",
        "                    nc[i] = False\n",
        "            for i in SUB_TABLE_ADD:\n",
        "                if nc[i]:\n",
        "                    curr_sym_split[1] += SUB_TABLE_ADD[i]\n",
        "                    nc[i] = False\n",
        "            curr_sym = curr_sym_split[0]+curr_sym_split[1]\n",
        "\n",
        "            if SUB_TABLE_ADD[\"labialization\"] in curr_sym and SUB_TABLE_ADD[\"palatal\"] in curr_sym:\n",
        "                curr_sym = curr_sym.replace(SUB_TABLE_ADD[\"labialization\"], \"·∂£\")\n",
        "                curr_sym = curr_sym.replace(SUB_TABLE_ADD[\"palatal\"], \"\")\n",
        "\n",
        "            # Long sound and stress\n",
        "            if output[CRITERIA_TAGS_ID[\"lon\"]] >= 0.5:\n",
        "                curr_sym += \"Àê\"\n",
        "            if output[CRITERIA_TAGS_ID[\"str\"]] >= 0.5:\n",
        "                curr_sym = \"Àà\"+curr_sym\n",
        "\n",
        "        # Adding spacing\n",
        "        curr_sym += spacing\n",
        "\n",
        "        whole_symbol_notation += curr_sym\n",
        "    return whole_symbol_notation"
      ],
      "metadata": {
        "id": "VskM0TRYSDUi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p4Tl_5JQRKxL"
      },
      "outputs": [],
      "source": [
        "torch.set_printoptions(precision=8)\n",
        "# DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "kernel_size = 15\n",
        "num_layers = 4\n",
        "old_version = True\n",
        "\n",
        "# audio_path = \"./zzzzzzz.wav\"\n",
        "def audio_to_ipa(audio_path=\"./audio.mp3\", saving=True, think_value=0.5):\n",
        "    audio_frames = audio_reformatting(audio_path)\n",
        "    with torch.no_grad():\n",
        "        hidden = MODEL.init_hidden()\n",
        "        outputs = []\n",
        "        for audio_frame in audio_frames:\n",
        "            audio_frame = torch.from_numpy(audio_frame).unsqueeze(0).unsqueeze(0)\n",
        "            output, hidden = MODEL(audio_frame, hidden)\n",
        "            outputs.append(output.to(DEVICE))\n",
        "        collected_outputs = [[float(j) for j in i[0][0]] for i in outputs]\n",
        "        ipa = output_to_symbols(collected_outputs, think_value)\n",
        "        if saving:\n",
        "            with open(audio_path+\".txt\", 'w', encoding=\"utf8\") as f:\n",
        "                f.write(ipa)\n",
        "        return ipa\n",
        "\n",
        "def multiple_audio_to_ipa(audio_paths:list, saving=True, think_value=0.5):\n",
        "    return [[audio_path, audio_to_ipa(audio_path, saving, think_value)] for audio_path in audio_paths]\n",
        "\n",
        "def save_all(ipas:list, folder_path:str):\n",
        "    with open(folder_path+\"!all_files.txt\", 'w', encoding=\"utf8\") as f:\n",
        "        for ipa in ipas:\n",
        "            f.write(f\"{ipa[0]}\\t{ipa[1]}\\n\")\n",
        "\n",
        "SUPPORTED_FILES = [\".mp3\", \".ogg\", \".wav\", \".flac\", \".m4a\"]\n",
        "def folder_audio_to_ipa(folder_path:str, saving=True, think_value=0.5):\n",
        "    import os\n",
        "    folder_path = folder_path.replace(\"\\\\\", \"/\")\n",
        "    folder_path = folder_path if folder_path[-1] == \"/\" else folder_path+\"/\"\n",
        "    all_folder_files = os.listdir(path=folder_path)\n",
        "\n",
        "    audio_folder_files = []\n",
        "    for file in all_folder_files:\n",
        "        full_file_path = folder_path+file\n",
        "        _, file_extension = os.path.splitext(full_file_path)\n",
        "        if file_extension in SUPPORTED_FILES:\n",
        "            audio_folder_files.append(full_file_path)\n",
        "    ipas = multiple_audio_to_ipa(audio_folder_files, saving, think_value)\n",
        "    if saving:\n",
        "        save_all(ipas, folder_path)\n",
        "    return ipas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1CKfW-A6MZjGjpEaIe5UXkc0q_rjexN99\n",
        "!unzip \"listen_ipa_archive.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5Ragx_qV4MY",
        "outputId": "fb42bebf-9fa2-48ed-86d8-f56ca3369e43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CKfW-A6MZjGjpEaIe5UXkc0q_rjexN99\n",
            "To: /content/listen_ipa_archive.zip\n",
            "100% 10.2M/10.2M [00:00<00:00, 19.1MB/s]\n",
            "Archive:  listen_ipa_archive.zip\n",
            "   creating: data/\n",
            "   creating: data/audio_examples/\n",
            "  inflating: data/audio_examples/113.mp3  \n",
            "  inflating: data/audio_examples/13809.mp3  \n",
            "  inflating: data/audio_examples/13868.mp3  \n",
            "  inflating: data/audio_examples/153747.mp3  \n",
            "  inflating: data/audio_examples/165331.mp3  \n",
            "  inflating: data/audio_examples/22311.mp3  \n",
            "  inflating: data/audio_examples/22404.mp3  \n",
            "  inflating: data/audio_examples/22545.mp3  \n",
            "  inflating: data/audio_examples/228166.mp3  \n",
            "  inflating: data/audio_examples/228408.mp3  \n",
            "  inflating: data/audio_examples/259561.mp3  \n",
            "  inflating: data/examples.json      \n",
            "  inflating: !!!test.wav             \n",
            "  inflating: model_epoch_1.pth       \n",
            "  inflating: model_epoch_2.pth       \n",
            "  inflating: model_epoch_3.pth       \n",
            "  inflating: model_new_epoch_1.pth   \n",
            "  inflating: model_new_epoch_2.pth   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"
      ],
      "metadata": {
        "id": "wmtH5WL3dV9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å\n",
        "epoch = 1\n",
        "old_version = True\n",
        "\n",
        "MODEL = ListenIPA(513, CRITERIA_LEN, kernel_size, num_layers, old_version)\n",
        "model_path = f'/content/model{\"\" if old_version else \"_new\"}_epoch_{epoch}.pth'\n",
        "MODEL.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "MODEL.eval()"
      ],
      "metadata": {
        "id": "ZmxSx4zfSQL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ –≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é"
      ],
      "metadata": {
        "id": "FXDe1sGZdn5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(audio_to_ipa(\"/content/!!!test.wav\", think_value=0.5))\n",
        "for i in folder_audio_to_ipa('/content/data/audio_examples/', think_value=0.5):\n",
        "    print(i[0], i[1], sep=\"\\t\")"
      ],
      "metadata": {
        "id": "cSw2olmzdlwV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}